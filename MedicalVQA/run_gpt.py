import argparse
from data import MedicalVQADataset
from prompt_builder import *
from openai import OpenAI
from utils import *
from retrieval import *

client = OpenAI()

def get_gpt_result(prompt):
    resp = client.responses.create(
        model="gpt-4o",
        input=prompt,
        temperature=0,
        max_output_tokens=512,
    )
    return resp.output_text.strip()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # None, "SimpleMultimodalRetriever", "SimpleTextRetriever", "RandomRetriever"
    parser.add_argument('--retriever', type=str, default="SimpleMultimodalRetriever", help='Retriever') 
    # 'slake', 'vqa_rad', 'pathvqa'
    parser.add_argument("--dataset", type=str, default='slake')

    args = parser.parse_args()

    vqa_data = MedicalVQADataset(args.dataset, split="test")

    if args.retriever == "SimpleMultimodalRetriever":
        retriever = SimpleMultimodalRetriever(kg_path="MedMKG_huggingface/MedMKG.csv", image_map_path="MedMKG_huggingface/image_mapping.csv", model_name="clip-ViT-B-32")
    elif args.retriever == "RandomRetriever":
        retriever = RandomRetriever(kg_path="MedMKG_huggingface/MedMKG.csv", image_map_path="MedMKG_huggingface/image_mapping.csv")
    elif args.retriever == "SimpleTextRetriever":
        retriever = SimpleTextRetriever(kg_path="MedMKG_huggingface/MedMKG.csv", image_map_path="MedMKG_huggingface/image_mapping.csv", model_name="sentence-transformers/all-MiniLM-L6-v2")
    
    outputs = []
    answers = []

    for sample in vqa_data.samples[:10]:
        prompt = build_multimodal_input_for_sample(sample)
        if args.retriever:
            retrieved_items = retriever.search(sample, 3)
            rag_prompt = build_rag_prompt(retrieved_items, retriever.image_id_to_path)
            prompt[1]["content"] = rag_prompt + prompt[1]["content"]
        outputs.append(int(get_gpt_result(prompt)))
        answers.append(int(sample["answer"]))

    print(compute_metrics(answers, outputs))